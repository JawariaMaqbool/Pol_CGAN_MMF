{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmMj_rD2rusq"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader , random_split\n",
        "from torchsummary import summary\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import Adam , lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import trange, tqdm\n",
        "!pip install torchmetrics\n",
        "from torchmetrics import StructuralSimilarityIndexMeasure\n",
        "import time\n",
        "import itertools\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms.functional import center_crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znYYQDrJ8-9R"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive  # mounting the drive to access the data stored on it\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95w9Jck3rw5N"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, dilation=1, groups=1, bias=False,\n",
        "                 do_norm=True, norm = 'batch', do_activation = True): # bias default is True in Conv2d\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "        self.leakyRelu = nn.LeakyReLU(0.2, True)\n",
        "        self.do_norm = do_norm\n",
        "        self.do_activation = do_activation\n",
        "        if do_norm:\n",
        "            if norm == 'batch':\n",
        "                self.norm = nn.BatchNorm2d(out_channels)\n",
        "            elif norm == 'instance':\n",
        "                self.norm = nn.InstanceNorm2d(out_channels)\n",
        "            elif norm == 'none':\n",
        "                self.do_norm = False\n",
        "            else:\n",
        "                raise NotImplementedError(\"norm error\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.do_activation:\n",
        "            x = self.leakyRelu(x)\n",
        "\n",
        "        x = self.conv(x)\n",
        "\n",
        "        if self.do_norm:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False,\n",
        "                 do_norm=True, norm = 'batch',do_activation = True, dropout_prob=0.2):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.drop = nn.Dropout2d(dropout_prob)\n",
        "        self.do_norm = do_norm\n",
        "        self.do_activation = do_activation\n",
        "        if do_norm:\n",
        "            if norm == 'batch':\n",
        "                self.norm = nn.BatchNorm2d(out_channels)\n",
        "            elif norm == 'instance':\n",
        "                self.norm = nn.InstanceNorm2d(out_channels)\n",
        "            elif norm == 'none':\n",
        "                self.do_norm = False\n",
        "            else:\n",
        "                raise NotImplementedError(\"norm error\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.do_activation:\n",
        "            x = self.relu(x)\n",
        "\n",
        "        x = self.convT(x)\n",
        "\n",
        "        if self.do_norm:\n",
        "           x = self.norm(x)\n",
        "\n",
        "        if self.dropout_prob != 0:\n",
        "            x= self.drop(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRqcWti7r51O"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, bias = False, dropout_prob=0.2, norm = 'batch'):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # 8-step encoder\n",
        "        self.encoder1 = EncoderBlock(in_channels, 64, bias=bias, do_norm=False, do_activation=False)\n",
        "        self.encoder2 = EncoderBlock(64, 128, bias=bias, norm=norm)\n",
        "        self.encoder3 = EncoderBlock(128, 256, bias=bias, norm=norm)\n",
        "        self.encoder4 = EncoderBlock(256, 512, bias=bias, norm=norm)\n",
        "        self.encoder5 = EncoderBlock(512, 512, bias=bias, norm=norm)\n",
        "        self.encoder6 = EncoderBlock(512, 512, bias=bias, norm=norm)\n",
        "        self.encoder7 = EncoderBlock(512, 512, bias=bias, norm=norm)\n",
        "        self.encoder8 = EncoderBlock(512, 512, bias=bias, do_norm=False)\n",
        "\n",
        "        # 8-step UNet decoder\n",
        "        self.decoder1 = DecoderBlock(512, 512, bias=bias, norm=norm)\n",
        "        self.decoder2 = DecoderBlock(1024, 512, bias=bias, norm=norm, dropout_prob=dropout_prob)\n",
        "        self.decoder3 = DecoderBlock(1024, 512, bias=bias, norm=norm, dropout_prob=dropout_prob)\n",
        "        self.decoder4 = DecoderBlock(768, 256, bias=bias, norm=norm, dropout_prob=dropout_prob)\n",
        "        self.decoder5 = DecoderBlock(256, 128, bias=bias, norm=norm)\n",
        "        # self.decoder6 = DecoderBlock(128, 64, bias=bias, norm=norm)\n",
        "        # self.decoder7 = DecoderBlock(64, 32, bias=bias, norm=norm)\n",
        "        self.decoder8 = DecoderBlock(128, out_channels, bias=bias, do_norm=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 8-step encoder\n",
        "        encode1 = self.encoder1(x)\n",
        "        encode2 = self.encoder2(encode1)\n",
        "        encode3 = self.encoder3(encode2)\n",
        "        encode4 = self.encoder4(encode3)\n",
        "        encode5 = self.encoder5(encode4)\n",
        "        encode6 = self.encoder6(encode5)\n",
        "        # encode7 = self.encoder7(encode6)\n",
        "        # encode8 = self.encoder8(encode6)\n",
        "\n",
        "        # 8-step UNet decoder\n",
        "        decode1 = torch.cat([self.decoder1(encode6), encode5],1)\n",
        "        decode2 = torch.cat([self.decoder2(decode1), encode4],1)\n",
        "        decode3 = torch.cat([self.decoder3(decode2), encode3],1)\n",
        "        decode4 = self.decoder4(decode3)\n",
        "        decode5 = self.decoder5(decode4)\n",
        "        # decode6 = self.decoder6(decode5)\n",
        "        # decode7 = self.decoder7(decode6)\n",
        "        decode8 = self.decoder8(decode5)\n",
        "        final = self.tanh(decode8)\n",
        "        return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q_jnyEir-xg"
      },
      "outputs": [],
      "source": [
        "#############################################################\n",
        "# patchGAN\n",
        "#############################################################\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, bias = False, norm = 'batch', sigmoid=True):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # 70x70 discriminator\n",
        "        self.disc1 = EncoderBlock(in_channels * 2, 64, bias=bias, do_norm=False, do_activation=False)\n",
        "        self.disc2 = EncoderBlock(64, 128, bias=bias, norm=norm)\n",
        "        self.disc3 = EncoderBlock(128, 256, bias=bias, norm=norm)\n",
        "        self.disc4 = EncoderBlock(256, 512, bias=bias, norm=norm, stride=1)\n",
        "        self.disc5 = EncoderBlock(512, out_channels, bias=bias, stride=1, do_norm=False)\n",
        "        self.linear = nn.Linear(36,1)\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "    def forward(self, x, ref):\n",
        "        d1 = self.disc1(torch.cat([x, ref],1))\n",
        "        d2 = self.disc2(d1)\n",
        "        d3 = self.disc3(d2)\n",
        "        d4 = self.disc4(d3)\n",
        "        d5 = self.disc5(d4)\n",
        "        d6  = self.flat(d5)\n",
        "        d7 = self.linear(d6)\n",
        "        final = self.sigmoid(d7)\n",
        "        return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AYiHOWFsd9I"
      },
      "outputs": [],
      "source": [
        "device=None\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda:0'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krgxx36FsXGJ"
      },
      "outputs": [],
      "source": [
        "summary(Generator().to(device),(1,64,64))\n",
        "summary(Discriminator().to(device),[(1,64,64),(1,64,64)])  #change this to discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8YNS-Z2872J"
      },
      "outputs": [],
      "source": [
        "# This is the custom Data Loader class\n",
        "\n",
        "class Speckle(Dataset):\n",
        "    def __init__(self): # add additional parameters needed to load the dataset e.g dataset path\n",
        "\n",
        "        self.data= np.load('speckle training data path', allow_pickle=True)\n",
        "        self.label=np.load('MNIST label path' , allow_pickle=True)\n",
        "        print(self.data.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        speckle=self.data[idx]   # picks the images based on the random index generated\n",
        "        #speckle= cv2.cvtColor(speckle, cv2.COLOR_BGR2GRAY)    # read the image as grayscale instead of the cv2 default of BGR\n",
        "        speckle_img=speckle/255.0\n",
        "        speckle_img = cv2.resize(speckle_img, (64,64), interpolation= cv2.INTER_LANCZOS4)\n",
        "        speckle_img = speckle_img.reshape(64,64,1)  # reshape the image from 256 x 256 to 256 x 256 x 1\n",
        "        speckle_img=speckle_img.astype(np.float32)    # Asert the data type to be float\n",
        "        speckle_img=speckle_img.T                     # transpose the image as this is the convention for pytorch where filters should come first\n",
        "        speckle_img_tensor = torch.from_numpy(speckle_img)  # convert from numpy array to pytorch tensor\n",
        "\n",
        "        #Follow the same steps for label preprocessig as well\n",
        "\n",
        "        label_img=self.label[idx]\n",
        "        label_img= cv2.cvtColor(label_img, cv2.COLOR_BGR2GRAY)\n",
        "        label_img=label_img/255.0\n",
        "        label_img = cv2.resize(label_img, (64,64), interpolation= cv2.INTER_LANCZOS4)\n",
        "        #label_img= np.array([label_img], order='C')\n",
        "        #datas.resize((1,28,28))\n",
        "        label_img = label_img.reshape(64,64,1)\n",
        "        label_img=label_img.astype(np.float32)\n",
        "        label_img=label_img.T\n",
        "        label_img_tensor = torch.from_numpy(label_img)\n",
        "\n",
        "\n",
        "        return speckle_img_tensor, label_img_tensor  # return data and label pair as a tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3I8D7pJ9IyF"
      },
      "outputs": [],
      "source": [
        "speckle_test = Speckle()\n",
        "print(len(speckle_test))\n",
        "#randomly split the data into three, with 70% for training, 20% for validation and 10% for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,valid = random_split(speckle_test, lengths=[int(len(speckle_test)*0.9), int(len(speckle_test)*0.1)])\n",
        "print(len(train),len(valid))"
      ],
      "metadata": {
        "id": "_bJvZgaJtpKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4OyhC29Nj5"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "'''\n",
        "We will be pasing the images in batches and can be set based on gpu memory. The images are also shuffled and picked randomly\n",
        "'''\n",
        "batch_size = 40\n",
        "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
        "#test_dataloader = DataLoader(test, batch_size=1, shuffle=True)\n",
        "print(len(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7ltNX-ksnuq"
      },
      "outputs": [],
      "source": [
        "desc_loss_fn = torch.nn.BCELoss()\n",
        "gen_loss_fn = torch.nn.MSELoss()\n",
        "L1_loss = torch.nn.L1Loss()\n",
        "def gan_loss( out, label, mode ):\n",
        "  if mode == 'desc':\n",
        "    return desc_loss_fn(out, torch.ones_like(out) if label else torch.zeros_like(out))\n",
        "  if mode == 'gen':\n",
        "    return gen_loss_fn(out, torch.ones_like(out) if label else torch.zeros_like(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlgqkjoi6tjb"
      },
      "outputs": [],
      "source": [
        "lr=0.0001\n",
        "D=Discriminator().to(device)\n",
        "G=Generator().to(device)\n",
        "optimizer_D=torch.optim.Adam(D.parameters(),lr=lr)\n",
        "optimizer_G=torch.optim.Adam(G.parameters(),lr=lr)\n",
        "scheduler_T_max = 5  # You can adjust this value based on your preference\n",
        "scheduler_D = CosineAnnealingLR(optimizer_D, T_max=scheduler_T_max, eta_min=0)\n",
        "scheduler_G = CosineAnnealingLR(optimizer_G, T_max=scheduler_T_max, eta_min=0)\n",
        "lambd_d = 0.5\n",
        "lambd = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEYq-tcX6M6M"
      },
      "outputs": [],
      "source": [
        "last_loss_g = 99999999999999999999.0\n",
        "last_loss_d = 99999999999999999999.0\n",
        "\n",
        "ld_real =[]\n",
        "ld_fake =[]\n",
        "lg_gan =[]\n",
        "lg_l1 = []\n",
        "ld = []\n",
        "lg =[]\n",
        "\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(120)):\n",
        "\n",
        "  D.train()\n",
        "  G.train()\n",
        "  losses_G,losses_D=[],[]\n",
        "  for i,(x,y) in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "      x=x.to(device)\n",
        "      y=y.to(device)\n",
        "\n",
        "      ############################\n",
        "      # D loss\n",
        "      ############################\n",
        "      optimizer_D.zero_grad()\n",
        "\n",
        "      gen = G(x)\n",
        "      # real y and x -> 1\n",
        "      loss_D_real = gan_loss(D(y, x), 1, 'desc') * lambd_d\n",
        "      # gen and x -> 0\n",
        "      loss_D_fake = gan_loss(D(gen.detach(), x), 0, 'desc') * lambd_d\n",
        "      # Combine\n",
        "      loss_D = loss_D_real + loss_D_fake\n",
        "\n",
        "      loss_D.backward()\n",
        "      optimizer_D.step()\n",
        "      # loss_D.backward()\n",
        "      # optimizer_D.step()\n",
        "\n",
        "    ##############\n",
        "      # G loss\n",
        "      ############################\n",
        "      optimizer_G.zero_grad()\n",
        "\n",
        "      # gen = G(x)\n",
        "      # GAN loss of G\n",
        "      loss_G_gan = gan_loss(D(gen, x), 1, 'gen')\n",
        "      # L1 loss of G\n",
        "      loss_G_L1 = L1_loss(gen, y) * lambd\n",
        "      # Combine\n",
        "      loss_G = loss_G_gan + loss_G_L1\n",
        "\n",
        "      loss_G.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "  scheduler_D.step()\n",
        "  scheduler_G.step()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    plt.figure()\n",
        "    generated_imgs=G(x[:5])\n",
        "    real_imgs=x[:5]\n",
        "    imgs=torch.cat([generated_imgs,real_imgs,y[:5]],0).data.cpu()\n",
        "    grid=make_grid(imgs,nrow=5).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()\n",
        "  print(f'G {loss_G} G_gan {loss_G_gan} G_L1: {loss_G_L1} D: {loss_D} D_real: {loss_D_real} D_fake: {loss_D_fake}')\n",
        "  ld_real.append(float(loss_D_real))\n",
        "  ld_fake.append(float(loss_D_fake))\n",
        "  lg_gan.append(float(loss_G_gan))\n",
        "  lg_l1.append(float(loss_G_L1))\n",
        "  ld.append(float(loss_D))\n",
        "  lg.append(float(loss_G))\n",
        "\n",
        "  torch.save(G.state_dict(),'/content/drive/MyDrive/weights/abc_gen.pt')\n",
        "  torch.save(D.state_dict(), '/content/drive/MyDrive/weights/abc_dis.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ld, 'k-', label=\"D\")\n",
        "plt.plot(lg, 'c-', label=\"G\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xP8PmXMYuKPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ld_real, 'g-', label=\"D_real\")\n",
        "plt.plot(ld_fake, 'r-', label=\"D_fake\")\n",
        "plt.plot(lg_gan, 'y-', label=\"G_gan\")\n",
        "plt.plot(lg_l1, 'b-', label=\"G_L1\")"
      ],
      "metadata": {
        "id": "V7KTZ40GawlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZx_cPAx9pnF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TestData(Dataset):\n",
        "    def __init__(self): # add additional parameters needed to load the dataset e.g dataset path\n",
        "        # your code here.\n",
        "\n",
        "        self.data= np.load('speckle test data path', allow_pickle=True)\n",
        "        self.label=np.load('MNIST label data path' , allow_pickle=True)[55000:60000]\n",
        "        print(self.data.shape)\n",
        "        print(self.label.shape)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "        # return 30000\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        speckle=self.data[idx]   # picks the images based on the random index generated\n",
        "        # speckle= cv2.cvtColor(speckle, cv2.COLOR_BGR2GRAY)    # read the image as grayscale instead of the cv2 default of BGR\n",
        "        speckle_img=speckle/255.0\n",
        "        speckle_img = cv2.resize(speckle_img, (64,64), interpolation= cv2.INTER_LANCZOS4)\n",
        "        speckle_img = speckle_img.reshape(64,64,1)  # reshape the image from 256 x 256 to 256 x 256 x 1\n",
        "        speckle_img=speckle_img.astype(np.float32)    # Asert the data type to be float\n",
        "        speckle_img=speckle_img.T                     # transpose the image as this is the convention for pytorch where filters should come first\n",
        "        speckle_img_tensor = torch.from_numpy(speckle_img)  # convert from numpy array to pytorch tensor\n",
        "\n",
        "        #Follow the same steps for label preprocessig as well\n",
        "\n",
        "        label_img=self.label[idx]\n",
        "        label_img= cv2.cvtColor(label_img, cv2.COLOR_BGR2GRAY)\n",
        "        label_img=label_img/255.0\n",
        "        label_img = cv2.resize(label_img, (64,64), interpolation= cv2.INTER_LANCZOS4)\n",
        "        label_img = label_img.reshape(64,64,1)\n",
        "        label_img=label_img.astype(np.float32)\n",
        "        label_img=label_img.T\n",
        "        label_img_tensor = torch.from_numpy(label_img)\n",
        "\n",
        "\n",
        "\n",
        "        return speckle_img_tensor, label_img_tensor  # return data and label pair as a tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader2 = DataLoader(TestData(), batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "U43Oqazro9bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speckle=None\n",
        "predicted=None\n",
        "lab=None\n",
        "print(device)\n",
        "total = []\n",
        "ssim = StructuralSimilarityIndexMeasure().to(device)\n",
        "u_net = Generator()\n",
        "u_net.load_state_dict(torch.load('/content/drive/MyDrive/weights/abc_gen.pt',map_location=torch.device(device)))\n",
        "u_net.to(device)\n",
        "u_net.eval()\n",
        "count = 0\n",
        "for data,label in test_dataloader2:\n",
        "  data=data.to(device)\n",
        "  predicted =u_net(data)\n",
        "  lab=label.to(device)\n",
        "\n",
        "  predicted=predicted.to(device)\n",
        "  val = ssim(lab,predicted.reshape(data.shape[0],1,64,64)).item()\n",
        "  total.append(val)\n",
        "  if count <20 :\n",
        "    count = count+1\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(lab[0].reshape(64,64).T.cpu().detach(),cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(predicted[0].reshape(64,64).T.cpu().detach(),cmap='gray')\n",
        "\n",
        "    print(\"SSIM VALUE = \" , val)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"maximum SSIM: = \", max(total))\n",
        "print(\"Average SSIM Value = \",sum(total)/len(total))"
      ],
      "metadata": {
        "id": "zCaZq0V7pBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wz6z3B_npSNS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}